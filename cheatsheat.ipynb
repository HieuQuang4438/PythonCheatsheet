{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\t# or \n",
    "\t# from datetime import datetime as dt, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Import & Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', 100) # 100 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "\n",
    "df = pd.read_excel(\"Data\\sales.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df.tail()\n",
    "df.sample()\n",
    "df.shape\n",
    "df.columns\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Important Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using df.iloc[90:100] -> the end index is `not inclusive`\n",
    "- using df.loc[90:100] -> the end index is `inclusive`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Handling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.duplicated(subset=None, keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- subset: Columns to check for duplicates. By default, all columns are used.\n",
    "- keep: Determines which duplicates (if any) to mark as False.\n",
    "    - 'first': Mark duplicates as True, except for the first occurrence.\n",
    "    - 'last': Mark duplicates as True, except for the last occurrence.\n",
    "    - False: Mark all duplicates as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated() # show if a row is duplicted (true/false)\n",
    "df.duplicated().sum() # number of duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **subset**: Specifies which columns to consider for identifying duplicates. If left as `None`, all columns are considered.\n",
    "- **keep**: Determines which duplicates to keep.\n",
    "    - `'first'`: Keeps the first occurrence (default).\n",
    "    - `'last'`: Keeps the last occurrence.\n",
    "    - `False`: Drops all duplicates.\n",
    "- **inplace**: If `True`, performs the operation in place (modifying the original DataFrame). Otherwise, it returns a new DataFrame.\n",
    "- **ignore_index**: If `True`, resets the index after dropping duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Handling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df_no_missing_CustomerId = df.copy()\n",
    "df_no_missing_CustomerId.dropna(subset=['CustomerId'], inplace=True)\n",
    "df_no_missing_CustomerId.info()\n",
    "\n",
    "# project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **axis**:\n",
    "    - `0` or `'index'`: Drops rows (default).\n",
    "    - `1` or `'columns'`: Drops columns.\n",
    "- **how**:\n",
    "    - `'any'`: Drops a row/column if any of its values are NaN (default).\n",
    "    - `'all'`: Drops a row/column only if all of its values are NaN.\n",
    "- **thresh**: Requires that at least a certain number of non-NaN values are present for the row/column to be kept. For example, `thresh=2` means the row/column must have at least 2 non-NaN values to be retained.\n",
    "- **subset**: Specifies the subset of columns (or rows) to check for NaN values.\n",
    "- **inplace**: If `True`, modifies the original DataFrame; otherwise, returns a new DataFrame with the rows/columns dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling 0 or Negative Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df_no_missing_price = df_no_duplicate.copy()\n",
    "df_no_missing_price = df_no_missing_price[df_no_missing_price['UnitPrice'] > 0]\n",
    "df_no_missing_price.info()\n",
    "\n",
    "# project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- value: Scalar, dictionary, Series, or DataFrame. The value(s) to replace NaNs with.\n",
    "- method: {'backfill', 'bfill', 'pad', 'ffill'}, default None. Specifies the fill method.\n",
    "    - pad or ffill: Fill forward (use the last valid value to fill the next NaN).\n",
    "    - backfill or bfill: Fill backward (use the next valid value to fill the NaN).\n",
    "- axis: {0 or 'index', 1 or 'columns'}, default 0. The axis along which to fill missing values.\n",
    "- inplace: bool, default False. If True, fills the missing values in place without creating a new DataFrame.\n",
    "- limit: int, default None. The maximum number of NaNs to fill.\n",
    "- downcast: dict, default None. Specifies if and how to downcast the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill with different values for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'column1': 0, 'column2': 'missing'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Handling Datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# format data type of order_date and 'Customer Since' from object to datetime\n",
    "\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%m/%d/%Y') \n",
    "\t\n",
    "\t# format='%m/%d/%Y' is the old format when it was object (string)\n",
    "\t# new format is 'YYYY-MM-DD', eg: 2006-08-22\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting YearMonth, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "da['OrderMonth'] = da['OrderDate'].dt.to_period('M')\n",
    "\t# eg output: 2020-10 \n",
    "da['YearAcquired'] = da['CustomerSince'].dt.to_period('Y')\n",
    "\t\n",
    "\t# the output type is 'period' <> 'datetime'\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# change datatype of YearAcquired to int for easier acquisition\n",
    "da.YearAcquired = da.YearAcquired.astype('str')\n",
    "da.YearAcquired = da.YearAcquired.astype('int64')\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Manipulating Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Selecting Columns/Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df = df[['order_id', 'order_date', 'cust_id', 'Customer Since', 'qty_ordered', 'price', 'value', 'discount_amount', 'total']]\n",
    "df = df.drop(columns=['price', 'value', 'discount_amount'])\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **labels**: Single label or a list of labels to drop. It can be row indices or column names, depending on the axis.\n",
    "- **axis**:\n",
    "    - `0` or `'index'` for rows (default).\n",
    "    - `1` or `'columns'` for columns.\n",
    "- **index**: Alternative to specifying row labels.\n",
    "- **columns**: Alternative to specifying column labels.\n",
    "- **level**: If working with a MultiIndex, this specifies which level to remove.\n",
    "- **inplace**: If `True`, modifies the original DataFrame. Otherwise, it returns a new DataFrame.\n",
    "- **errors**:\n",
    "    - `'raise'` (default): Raises an error if the labels are not found.\n",
    "    - `'ignore'`: Silently ignores the labels if they are not found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "da = pd.DataFrame(df.groupby(['OrderDate', 'OrderId', 'CustomerId']).agg({'CustomerSince': min, 'Quantity': sum, 'Sales': sum})).reset_index()\n",
    "\n",
    "TotalCustomer = pd.DataFrame(da.groupby('Cohorts', as_index=False).agg({'CustomerId': 'nunique'}))\n",
    "TotalCustomer.columns = ['Cohorts', 'TotalCustomer']\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "CustomerAcquired = pd.pivot_table(da, # dataframe\n",
    "                                  index='Cohorts',\n",
    "                                  columns='OrderMonth',\n",
    "                                  values='CustomerId',\n",
    "                                  aggfunc=pd.Series.nunique)\n",
    "\n",
    "# divide by a series                                  \n",
    "CustomerAcquiredPct = CustomerAcquired.div(TotalCustomer.iloc[:,1].values, axis=0)\n",
    "CustomerAcquiredPct\n",
    "\t# The `div()` function is used to perform element-wise division.\n",
    "\t# The `axis=0` argument specifies that the operation should be performed row-wise (meaning divide each row of `CustomerAcquired` by the corresponding row of `TotalCustomer.iloc[:,1]`).\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.div(..., axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.div(other, axis='columns', level=None, fill_value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **other**:\n",
    "    - The object to divide with (another DataFrame, Series, or scalar).\n",
    "- **axis**:\n",
    "    - `0` or `'index'`: Divides row-wise (meaning divide each row of `df` by the corresponding row of `other`).\n",
    "    - `1` or `'columns'`: Divides column-wise (default).\n",
    "- **level**:\n",
    "    - Specifies which level of a multi-index to broadcast along (useful when working with multi-index DataFrames).\n",
    "- **fill_value**:\n",
    "    - Value to use when `NaN` is found in either the DataFrame or the other object. Helps to avoid `NaN` results from dividing by `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df_no_missing_price[df_no_missing_price['InvoiceNumber'].str.startswith('C', na=False)].nunique()\n",
    "# na=False treats NaN values as False\n",
    "# nunique() to count the number of unique values \n",
    "\n",
    "# project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str.startswith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df_no_missing_price[df_no_missing_price['InvoiceNumber'].str.startswith('C', na=False)].nunique()\n",
    "# na=False treats NaN values as False\n",
    "# nunique() to count the number of unique values \n",
    "\n",
    "# project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Maplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sns.barplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "sns.barplot(data=TotalCustomer, x='Cohorts', y='TotalCustomer', palette='mako')\n",
    "plt.title('Number of Customers by Cohort')\n",
    "plt.xlabel('Acquisition Year')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sns.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: heatmap of number\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "sns.heatmap(CustomerAcquired, annot=True, annot_kws={'size':7}, fmt='.0f', linewidths=.4, cmap='Blues', cbar_kws={'label': 'Number of Customers'})\n",
    "plt.title('Number of Customers by Cohort over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Acquisition Year')\n",
    "plt.show()\n",
    "\n",
    "# example: heatmap of pct\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "sns.heatmap(CustomerAcquiredPct, annot=True, annot_kws={\"size\": 7}, fmt=\".2%\", linewidths = .4, cmap=\"OrRd\", cbar_kws={'label': 'Retention Rate'})\n",
    "plt.title('Retention Rate by Cohort over Time', fontsize = 12)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Acquisition Year')\n",
    "plt.show()\n",
    "\n",
    "# project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
